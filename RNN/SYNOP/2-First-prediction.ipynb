{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62e588b-aafd-411d-b201-18de41bd1c05",
   "metadata": {},
   "source": [
    "\n",
    "# <!-- TITLE -->  First predictions at 3h\n",
    "\n",
    "\n",
    "## Objectives :\n",
    " - Make a simple prediction (3h)\n",
    " - Understanding the use of a recurrent neural network\n",
    "\n",
    "\n",
    "SYNOP meteorological data, available at: https://public.opendatasoft.com\n",
    "\n",
    "## What we're going to do :\n",
    "\n",
    " - Read our dataset\n",
    " - Select our data and normalize it\n",
    " - Doing our training\n",
    " - Making simple predictions\n",
    "\n",
    "## Step 1 - Import and init\n",
    "### 1.1 - Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a149c-9828-490a-a1a3-cc15c6cf02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import h5py, json\n",
    "import os,time,sys\n",
    "\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b66ccc-4dce-4b72-a25d-962f96d6e0c5",
   "metadata": {},
   "source": [
    "### 1.2 - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674cece-7d9d-4efe-9394-7a0566f6b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- About dataset (no need to change)\n",
    "\n",
    "run_dir = '../run/SYNOP'\n",
    "dataset_dir = '../datasets/SYNOP/cleaned'\n",
    "dataset_filename = 'synop-LYS.csv'\n",
    "schema_filename  = 'synop.json'\n",
    "features         = ['tend', 'cod_tend', 'dd', 'ff', 'td', 'u', 'ww', 'pres', 'rafper', 'rr1', 'rr3', 'tc']\n",
    "features_len     = len(features)\n",
    "\n",
    "# ---- About training (Can be changed !)\n",
    "#\n",
    "scale            = 1        # Percentage of dataset to be used (1=all)\n",
    "train_prop       = .8       # Percentage for train (the rest being for the test)\n",
    "sequence_len     = 16\n",
    "batch_size       = 32\n",
    "epochs           = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1185244c-fded-4b24-b6df-3ea9f1730c07",
   "metadata": {},
   "source": [
    "## Step 2 - Read and prepare dataset\n",
    "### 2.1 - Read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22edc80f-b513-4ae1-b497-8f751f4b203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Read dataset from ./data\n",
    "\n",
    "df = pd.read_csv(f'{dataset_dir}/{dataset_filename}', header=0, sep=';')\n",
    "\n",
    "# ---- Scaling\n",
    "\n",
    "df = df[:int(scale*len(df))]\n",
    "train_len=int(train_prop*len(df))\n",
    "\n",
    "# ---- Train / Test\n",
    "dataset_train = df.loc[ :train_len-1, features ]\n",
    "dataset_test  = df.loc[train_len:,    features ]\n",
    "print('Train dataset example :')\n",
    "display(dataset_train.head(15))\n",
    "\n",
    "# ---- Normalize, and convert to numpy array\n",
    "\n",
    "mean = dataset_train.mean()\n",
    "std  = dataset_train.std()\n",
    "dataset_train = (dataset_train - mean) / std\n",
    "dataset_test  = (dataset_test  - mean) / std\n",
    "\n",
    "print('After normalization :')\n",
    "display(dataset_train.describe().style.format(\"{0:.2f}\"))\n",
    "\n",
    "dataset_train = dataset_train.to_numpy()\n",
    "dataset_test  = dataset_test.to_numpy()\n",
    "\n",
    "print('Shapes :')\n",
    "print('Dataset       : ',df.shape)\n",
    "print('Train dataset : ',dataset_train.shape)\n",
    "print('Test  dataset : ',dataset_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a797d-dfa1-4826-b7b2-e45a454cb25e",
   "metadata": {},
   "source": [
    "### 2.2 - Prepare data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413ce34-1cb3-4fde-b774-1a004e9371fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Train generator\n",
    "train_generator = TimeseriesGenerator(dataset_train, dataset_train, length=sequence_len,  batch_size=batch_size)\n",
    "test_generator  = TimeseriesGenerator(dataset_test,  dataset_test,  length=sequence_len,  batch_size=batch_size)\n",
    "\n",
    "# ---- About\n",
    "\n",
    "print('About the splitting of our dataset :')\n",
    "\n",
    "x,y=train_generator[0]\n",
    "print(f'Nombre de train batchs disponibles : ', len(train_generator))\n",
    "print('batch x shape : ',x.shape)\n",
    "print('batch y shape : ',y.shape)\n",
    "\n",
    "print('What a batch looks like (x) :')\n",
    "print(x[0] )\n",
    "print('What a batch looks like (y) :')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b5022f-9bd1-4f94-9e71-378f736327e3",
   "metadata": {},
   "source": [
    "## Step 3 - Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2a248-1ebd-4b2c-b9f2-d7b1492695f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add( keras.layers.InputLayer(input_shape=(sequence_len, features_len)) )\n",
    "model.add( keras.layers.LSTM(100, activation='relu') )\n",
    "model.add( keras.layers.Dropout(0.2) )\n",
    "model.add( keras.layers.Dense(features_len) )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c98fd-0bad-49a9-8521-e29935214ef3",
   "metadata": {},
   "source": [
    "## Step 4 - Compile and train\n",
    "### 4.1 - Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66bddb1-0519-4a0e-a378-5b6b37114e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(run_dir)\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "save_dir = f'{run_dir}/best_model.h5'\n",
    "bestmodel_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_dir, verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afa079-1036-434c-bf3e-a296df2f49d5",
   "metadata": {},
   "source": [
    "### 4.2 - Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1361736-50ae-465f-8fc9-4fedf2ee6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='mse', \n",
    "              metrics   = ['mae'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c572a22-f238-42eb-8c74-5f8d9b7e111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_generator, \n",
    "                  epochs=epochs, \n",
    "                 # verbose=10,\n",
    "                  validation_data = test_generator,\n",
    "                  callbacks = [bestmodel_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914b4e3-862f-4a5b-92bf-202306f493b1",
   "metadata": {},
   "source": [
    "## Step 5 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d4528-65d7-4f4a-a948-a88a683e4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(f'{run_dir}/best_model.h5')\n",
    "s=random.randint(0,len(dataset_test)-sequence_len)\n",
    "\n",
    "sequence      = dataset_test[s:s+sequence_len]\n",
    "sequence_true = dataset_test[s:s+sequence_len+1]\n",
    "\n",
    "pred = loaded_model.predict( np.array([sequence]) )\n",
    "# ---- Show result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b80275-ae05-47a3-9ea9-a6859867cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(mean,std,seq):\n",
    "    nseq = seq.copy()\n",
    "    for i,s in enumerate(nseq):\n",
    "        s = s*std + mean\n",
    "        nseq[i]=s\n",
    "    return nseq\n",
    "\n",
    "\n",
    "# ---- Get a sequence\n",
    "\n",
    "i=random.randint(0,len(dataset_test)-sequence_len)\n",
    "sequence      = dataset_test[i:i+sequence_len]\n",
    "sequence_true = dataset_test[i:i+sequence_len+1]\n",
    "\n",
    "# ---- Prediction\n",
    "\n",
    "pred = loaded_model.predict( np.array([sequence]) )\n",
    "\n",
    "# ---- De-normalization\n",
    "\n",
    "sequence_true = denormalize(mean,std, sequence_true)\n",
    "pred          = denormalize(mean,std, pred)\n",
    "\n",
    "# ---- Show it\n",
    "feat=11\n",
    "delta_deg=abs(sequence_true[-1][feat]-pred[-1][feat])\n",
    "print(f'Gap between prediction and reality : {delta_deg:.2f} Â°C')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e5101-e558-436a-946a-62edc2ef9475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dfc9e-34e9-4882-8777-9acb6dc2d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b080635-af4b-4d3c-83bb-b3313abe2dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036e123-64ea-477a-8353-a35207185d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4db0b-e3f2-4d16-91bd-b5a63475991f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3fa9b-95e1-44e8-94ad-2c86c46e8bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5aa561-26a3-4765-839b-66e5274466b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
